Title,Authors,Published,Link,Abstract_EN,Abstract_ZH,One_Sentence_Summary,Model_Type,HHH_Focus,Keywords
"AgentMisalignment: Measuring the Propensity for Misaligned Behaviour in
  LLM-Based Agents","Akshat Naik, Patrick Quinn, Guillermo Bosch, Emma Gouné, Francisco Javier Campos Zabala, Jason Ross Brown, Edward James Young",2025-06-04T14:46:47Z,http://arxiv.org/pdf/2506.04018v1,"As Large Language Model (LLM) agents become more widespread, associated
misalignment risks increase. Prior work has examined agents' ability to enact
misaligned behaviour (misalignment capability) and their compliance with
harmful instructions (misuse propensity). However, the likelihood of agents
attempting misaligned behaviours in real-world settings (misalignment
propensity) remains poorly understood. We introduce a misalignment propensity
benchmark, AgentMisalignment, consisting of a suite of realistic scenarios in
which LLM agents have the opportunity to display misaligned behaviour. We
organise our evaluations into subcategories of misaligned behaviours, including
goal-guarding, resisting shutdown, sandbagging, and power-seeking. We report
the performance of frontier models on our benchmark, observing higher
misalignment on average when evaluating more capable models. Finally, we
systematically vary agent personalities through different system prompts. We
find that persona characteristics can dramatically and unpredictably influence
misalignment tendencies -- occasionally far more than the choice of model
itself -- highlighting the importance of careful system prompt engineering for
deployed AI agents. Our work highlights the failure of current alignment
methods to generalise to LLM agents, and underscores the need for further
propensity evaluations as autonomous systems become more prevalent.",随着大型语言模型（LLM）代理的普及，相关的不一致风险也在增加。此前的研究已经检查了代理执行不一致行为（不一致能力）和遵守有害指令（滥用倾向）的能力。然而，代理在现实世界中尝试不一致行为的可能性（不一致倾向）仍然不为人知。我们引入了一个不一致倾向基准，AgentMisalignment，包括一套现实场景，其中LLM代理有机会表现出不一致行为。我们将评估分为不一致行为的子类别，包括目标保护、抵制关闭、拖延和寻求权力。我们报告了前沿模型在我们基准上的表现，观察到在评估更有能力的模型时，平均不一致性更高。最后，我们通过不同的系统提示系统地变化代理人格。我们发现，人格特征可以显著且不可预测地影响不一致倾向——有时远远超过模型本身的选择——强调了在部署AI代理时仔细系统提示工程的重要性。我们的工作突出了当前对齐方法无法推广到LLM代理的失败，并强调了随着自主系统变得更加普遍，进一步的倾向评估的需要。,The paper introduces a benchmark to measure the propensity for misaligned behavior in LLM-based agents and highlights the need for further alignment evaluations.,LLM,Harmless,"Misalignment, LLM agents, benchmark, propensity, alignment"
